<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="DPSVM : A distributed implementation of Support Vector Machines using OpenMPI and CUDA">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>DPSVM</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/thesiddharth/dpsvm">View on GitHub</a>

          <h1 id="project_title">DPSVM</h1>
          <h2 id="project_tagline">Distributed, Parallel Support Vector Machine training using OpenMPI and CUDA</h2>

			<section> <h5>
              <a href="http://thesiddharth.github.io/dpsvm/checkpoint.html"> Project Checkpoint </a> || <a href="http://thesiddharth.github.io/dpsvm/proposal.html"> Proposal </a>
            </h5> </section>
		  
            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/thesiddharth/dpsvm/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/thesiddharth/dpsvm/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h3>
<a id="summary" class="anchor" href="#summary" aria-hidden="true"><span class="octicon octicon-link"></span></a>Summary</h3>

<p dir="ltr">
	We have implemented a distributed and parallel <strong>Support Vector Machine</strong> training algorithm for binary classification using the <strong>OpenMPI</strong> library and the <strong>CUDA</strong> parallel programming model. We parallelize the modified Sequential Minimal Optimization algorithm used by popular tools like LIBSVM, and distribute the parallelism over <strong>GPUs</strong> in a cluster.
</p>

<h3>
<a id="background" class="anchor" href="#background" aria-hidden="true"><span class="octicon octicon-link"></span></a>Background</h3>

<p dir="ltr">
	The Support Vector Machine (<strong>SVM</strong>) is a widely used supervised machine learning algorithm, which is essentially a discriminative classifier used for linear and nonlinear classification tasks. The training of an SVM is a Quadratic Programming (QP) optimization problem. This QP is solved iteratively, where each update step involves the computation of the modified inner products of two training data input vectors (the <strong>kernel</strong> trick), which is computationally intensive over the set of all training data.
</p>
<p dir="ltr">
	We implement a parallel SMO algorithm which distributes the task of training over different nodes, as proposed by Cao et. al. <sup>[1]</sup> and extend it to multiple GPU devices based on Herrero-Lopez et. al.'s <sup>[2]</sup> methodology. We are using OpenMPI and CUDA to create a portable, high-performance implementation that leverages distributed environments.
</p>
<br/>
<p dir="ltr" class="centeredImage">
	<img
	src="images/workflow.png" width="556px;" height="401px;"/>
</p>
<br/>

<h3>
<a id="challenge" class="anchor" href="#challenge" aria-hidden="true"><span class="octicon octicon-link"></span></a>Challenges</h3>

<p dir="ltr">
	The aspect of the problem that is most challenging is parallelizing the kernel computations in a way that <strong><em>minimizes communication</em></strong> overheads between:
</p>
<ol>
	<li dir="ltr">
		<p dir="ltr">
			Nodes in the cluster
		</p>
	</li>
	<li dir="ltr">
		<p dir="ltr">
			GPU and CPU
		</p>
	</li>
</ol>

<p dir="ltr">
	For a single GPU implementation of a parallel SVM algorithm, <sup>[2]</sup> profiles time spent on communication versus computation on various training datasets. The following trends were noted:
</p>
<ol>
	<li dir="ltr">
		<p dir="ltr">
			Datasets with a large number of features per sample and a large number of samples spent most of the GPU time on computation (the <strong><em>kernel computation</em></strong>, which is a SGEMV matrix operation).
		</p>
	</li>
	<li dir="ltr">
		<p dir="ltr">
			Datasets with a relatively smaller number of features and samples were seen to spend up to 33% of GPU time on communication, during reductions and updates across GPU tasks.
		</p>
	</li>
</ol>
<p dir="ltr">
	Since we are are shifting this to a distributed environment, we would expect to see the communication-to-computation overhead increase. However, there exist even more <strong><em>complex datasets</em></strong> <sup>[3]</sup> that we expect to exhibit low ratios in our distributed environment as well.
</p>

<h3><a id="results" class="anchor" href="#results" aria-hidden="true"><span class="octicon octicon-link"></span></a>Current Status and Preliminary Results:</h3>
<p dir="ltr">
	We are done with the implementation of our training algorithm, and have also parallelized our classification approach over a single GPU. We are now in the process of profiling times with various datasets. Since we have implemented the SMO algorithm used by LibSVM, we get <strong>similar accuracy results and support-vector counts</strong>. Initial results on the popular <strong>Adult</strong>, <strong>MNIST</strong> and <strong>Forest Covertype</strong> datasets (Asuncion &amp; Newman, 2007) show the following training speedups over LibSVM:
</p>

<div dir="ltr">
	<table class="my_table">
		<colgroup>
			<col width="143"/>
			<col width="141"/>
			<col width="101"/>
			<col width="*"/>
		</colgroup>
		<tbody>
			<tr>
				<td class="setup_column">
					<strong> <p> Setup vs. Dataset </p> </strong>
				</td>
				<td class="info_column">
					<p dir="ltr">
						<strong>Adult</strong>
					</p>
				</td>
				<td class="info_column">
					<p dir="ltr">
						<strong>MNIST (Even vs Odd)</strong>
					</p>
				</td>
				<td class="info_column">
					<p dir="ltr">
						<strong>Covertype</strong>
					</p>
				</td>
			</tr>
			<tr>
				<td class="setup_column">
					<p dir="ltr">
						<strong>REFERENCE:</strong> Speedup achieved using single Tesla C1060
						<sup>[2]</sup>
					</p>
				</td>
				<td class="info_column">
					<p dir="ltr">
						10.45x
					</p>
				</td>
				<td class="info_column">
					<p dir="ltr">
						32.79x
					</p>
				</td>
				<td class="info_column">
					<p dir="ltr">
						-
					</p>
				</td>
			</tr>
			<tr>
				<td class="setup_column">
					<p dir="ltr">
						<strong>REFERENCE:</strong> Speedup achieved using chunking algorithm on three Tesla C1060s and one Intel Xeon E5426 2.8GHz	quad-core CPU. <sup>[3]</sup>
					</p>
				</td>
				<td class="info_column">
					<p dir="ltr">
						19.38x
					</p>
				</td>
				<td class="info_column">
					<p dir="ltr">
						129.64x
					</p>
				</td>
				<td class="info_column">
					<p dir="ltr">
						Too large for LibSVM,
					</p>
					<p dir="ltr">
						Runtime: 651s
					</p>
				</td>
			</tr>
			<tr>
				<td class="setup_column">
					<p dir="ltr">
						<strong>RESULT:</strong> Our Implementation on LATEDAYS (1 Tesla K40 on every node)
					</p>
				</td>
				<td class="info_column">
					<p dir="ltr">
						<strong>24x</strong>
					</p>
				</td>
				<td class="info_column">
					<p dir="ltr">
						<strong>124x</strong> (1 GPU) - <strong>531x</strong> (10 GPUs)
					</p>
				</td>
				<td class="info_column">
					<p dir="ltr">
						<strong>591 sec.</strong> (1 GPU)
					</p>
				</td>
			</tr>
		</tbody>
	</table>
</div>

<div>
	<img src="images/mnist_1.png" width="400px;" height="300px;"/>
	<img src="images/covertype_1.png" width="400px;" height="300px;"/>
</div>
<br/>

<div>
	<img src="images/mnist_2.png" width="400px;" height="300px;"/>
	<img src="images/covertype_2.png" width="400px;" height="300px;"/>
</div>
<br/> 

<div>
	<img src="images/mnist_3.png" width="400px;" height="300px;"/>
	<img src="images/covertype_3.png" width="400px;" height="300px;"/>
</div>
<br/>    

  <h3>
<a id="goals" class="anchor" href="#goals" aria-hidden="true"><span class="octicon octicon-link"></span></a>Goals and Deliverables</h3>

<p dir="ltr">
	<strong><em>Hope to achieve (by 11 May):</em></strong>
</p>

<ul>
	<li dir="ltr">
		<p dir="ltr">
			Profiling against Spark LIBLINEAR or MPI LIBLINEAR, <sup>[4]</sup>
		</p>
	</li>
	<li dir="ltr">
		<p dir="ltr">
			Extend the implementation to parallelize testing phase -- <strong> DONE </strong>
		</p>
	</li>
</ul>

  <h3>
<a id="platform" class="anchor" href="#platform" aria-hidden="true"><span class="octicon octicon-link"></span></a>Platform Choice</h3>

<p dir="ltr">
	We use the OpenMPI library and the CUDA parallel programming model on the latedays cluster. As mentioned above, this would allow us to create a portable implementation of our distributed SVM along with a high-performance GP-GPU pipeline targeted at latedays. The GPUs used are a Tesla K40 each on every node in the cluster.
</p>

  <h3>
<a id="bibliography" class="anchor" href="#bibliography" aria-hidden="true"><span class="octicon octicon-link"></span></a>Bibliography</h3>

<p dir="ltr">
	<sup>[1]</sup> Cao, Li Juan, et al. "Parallel sequential minimal optimization for the training of support vector machines." Neural Networks, IEEE Transactions on 17.4 (2006): 1039-1049.
</p>
<p dir="ltr">
	<sup>[2]</sup> Herrero-Lopez, Sergio, John R. Williams, and Abel Sanchez. "Parallel multiclass classification using SVMs on GPUs." Proceedings of the 3rd Workshop on General-Purpose Computation on Graphics Processing Units. ACM, 2010.
</p>
<p dir="ltr">
	<sup>[3]</sup> Li, Qi, et al. "Parallel multitask cross validation for Support Vector Machine using GPU." Journal of Parallel and Distributed Computing 73.3 (2013): 293-302.
</p>
<p dir="ltr">
	<sup>[4]</sup> http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/distributed-liblinear/
</p>


</body>
</html>
